{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIP21zu3NiVx"
      },
      "outputs": [],
      "source": [
        "pip install -q transformers datasets sentencepiece accelerate bitsandbytes peft scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLJHUteJNg67"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, torch, numpy as np\n",
        "from transformers import (AutoTokenizer, AutoModel,\n",
        "                          TrainingArguments, Trainer,\n",
        "                          DataCollatorWithPadding)\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import sklearn.metrics as skm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4zWx0QJcTCI"
      },
      "outputs": [],
      "source": [
        "MAX_SAMPLES = 100000\n",
        "SEED=42\n",
        "TRAITS = [\"O\", \"C\", \"E\", \"A\", \"N\"]\n",
        "RAW_COL = \"text\"\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NKmQr0P-cOzD"
      },
      "outputs": [],
      "source": [
        "def load_pandora_binary_data():\n",
        "    print(\"Loading Pandora dataset...\")\n",
        "\n",
        "    splits = {\n",
        "        'train': 'data/train-00001-of-00002.parquet',\n",
        "        'validation': 'data/validation-00000-of-00001.parquet',\n",
        "        'test': 'data/test-00000-of-00001.parquet'\n",
        "    }\n",
        "\n",
        "    train_df = pd.read_parquet('hf://datasets/jingjietan/pandora-big5/' + splits['train'])\n",
        "    if len(train_df) > MAX_SAMPLES:\n",
        "        train_df = train_df.sample(MAX_SAMPLES, random_state=SEED)\n",
        "\n",
        "    val_df = pd.read_parquet('hf://datasets/jingjietan/pandora-big5/' + splits['validation'])\n",
        "    if len(val_df) > MAX_SAMPLES // 5:\n",
        "        val_df = val_df.sample(MAX_SAMPLES // 5, random_state=SEED)\n",
        "\n",
        "    test_df = pd.read_parquet('hf://datasets/jingjietan/pandora-big5/' + splits['test'])\n",
        "    if len(test_df) > MAX_SAMPLES // 5:\n",
        "        test_df = test_df.sample(MAX_SAMPLES // 5, random_state=SEED)\n",
        "\n",
        "    print(f\"Dataset sizes: Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
        "\n",
        "    thresholds = {}\n",
        "    for trait in TRAITS:\n",
        "        thresholds[trait] = train_df[trait].median()\n",
        "        train_df[trait] = (train_df[trait] >= thresholds[trait]).astype(int)\n",
        "        val_df[trait] = (val_df[trait] >= thresholds[trait]).astype(int)\n",
        "        test_df[trait] = (test_df[trait] >= thresholds[trait]).astype(int)\n",
        "        print(f\"Median threshold for {trait}: {thresholds[trait]:.2f}\")\n",
        "\n",
        "    print(\"Class distribution:\")\n",
        "    for trait in TRAITS:\n",
        "        train_pos = train_df[trait].mean() * 100\n",
        "        val_pos = val_df[trait].mean() * 100\n",
        "        test_pos = test_df[trait].mean() * 100\n",
        "        print(f\"{trait}: Train {train_pos:.1f}% positive, Val {val_pos:.1f}% positive, Test {test_pos:.1f}% positive\")\n",
        "\n",
        "    return train_df, val_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnvIx1NMNjFJ",
        "outputId": "f291ee0d-90b3-4afa-e45e-09660eb8fb85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Pandora dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sizes: Train: 10000, Val: 2000, Test: 2000\n",
            "Median threshold for O: 38.00\n",
            "Median threshold for C: 68.00\n",
            "Median threshold for E: 31.00\n",
            "Median threshold for A: 33.00\n",
            "Median threshold for N: 50.00\n",
            "\n",
            "Class distribution:\n",
            "O: Train 51.1% positive, Val 51.8% positive, Test 51.6% positive\n",
            "C: Train 50.3% positive, Val 50.1% positive, Test 51.7% positive\n",
            "E: Train 50.2% positive, Val 50.7% positive, Test 51.3% positive\n",
            "A: Train 50.1% positive, Val 51.2% positive, Test 52.0% positive\n",
            "N: Train 52.3% positive, Val 52.5% positive, Test 53.9% positive\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df, test_df = load_pandora_binary_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pohMOEh1QLfk"
      },
      "outputs": [],
      "source": [
        "class PersonalityDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tok, max_len=512):\n",
        "        self.enc = tok(\n",
        "            list(df[\"text\"]),\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        self.labels = torch.tensor(\n",
        "            df[traits].to_numpy(dtype=np.float32),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "    def __len__(self):  return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: v[idx] for k, v in self.enc.items()}\n",
        "        item[\"labels\"] = self.labels[idx]\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4ZvieuPNorh"
      },
      "outputs": [],
      "source": [
        "class BertBig5(torch.nn.Module):\n",
        "    def __init__(self, mdl, pos_w):\n",
        "        super().__init__()\n",
        "        self.backbone = AutoModel.from_pretrained(mdl)\n",
        "        h = self.backbone.config.hidden_size\n",
        "        self.cls = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.Linear(h, h),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.Linear(h, 5)\n",
        "        )\n",
        "        self.crit = torch.nn.BCEWithLogitsLoss(pos_weight=pos_w)\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        x = self.backbone(input_ids, attention_mask).last_hidden_state[:,0]\n",
        "        logits = self.cls(x)\n",
        "        loss = self.crit(logits, labels) if labels is not None else None\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPttI-s9Ns4Q"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "    if not hasattr(compute_metrics, \"thr\"):\n",
        "        thr = []\n",
        "        for j in range(5):\n",
        "            best = max((skm.f1_score(labels[:,j], (probs[:,j]>t)),\n",
        "                        t) for t in np.linspace(0.1,0.9,17))[1]\n",
        "            thr.append(best)\n",
        "        compute_metrics.thr = np.array(thr)\n",
        "    pred = (probs > compute_metrics.thr).astype(int)\n",
        "    return {\"f1_macro\": skm.f1_score(labels, pred, average=\"macro\"),\n",
        "            \"f1_micro\": skm.f1_score(labels, pred, average=\"micro\"),\n",
        "            \"accuracy\":  skm.accuracy_score(labels, pred)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePAUZGZYQ-4E"
      },
      "outputs": [],
      "source": [
        "traits = [\"O\", \"C\", \"E\", \"A\", \"N\"]\n",
        "\n",
        "def enforce_numeric(df):\n",
        "    for t in traits:\n",
        "        df[t] = (\n",
        "            pd.to_numeric(df[t], errors=\"coerce\")\n",
        "              .fillna(0)\n",
        "              .astype(int)\n",
        "        )\n",
        "    return df\n",
        "\n",
        "train_df = enforce_numeric(train_df)\n",
        "val_df   = enforce_numeric(val_df)\n",
        "test_df  = enforce_numeric(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wdb3IvKN4Gg"
      },
      "outputs": [],
      "source": [
        "mdl_name   = \"bert-base-uncased\"\n",
        "tok        = AutoTokenizer.from_pretrained(mdl_name)\n",
        "traits     = [\"O\",\"C\",\"E\",\"A\",\"N\"]\n",
        "\n",
        "train_ds = PersonalityDataset(train_df, tok)\n",
        "val_ds   = PersonalityDataset(val_df, tok)\n",
        "test_ds  = PersonalityDataset(test_df, tok)\n",
        "\n",
        "pos_w = torch.tensor([(len(train_df)-train_df[t].sum())/train_df[t].sum() for t in traits])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeB3yczsNu8z"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    \"./big5\", eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
        "    metric_for_best_model=\"f1_macro\", load_best_model_at_end=True,\n",
        "    num_train_epochs=5, learning_rate=2e-5, weight_decay=0.01,\n",
        "    per_device_train_batch_size=16, gradient_accumulation_steps=2,\n",
        "    fp16=torch.cuda.is_available(), warmup_ratio=0.06, logging_steps=50)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model         = BertBig5(mdl_name, pos_w),\n",
        "    args          = args,\n",
        "    train_dataset = train_ds,\n",
        "    eval_dataset  = val_ds,\n",
        "    compute_metrics = compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "90LrJeO-Nv3v",
        "outputId": "4d6b949c-f222-42f0-c9f5-173e65c1f3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mposchyokotov\u001b[0m (\u001b[33mposchyokotov-hse-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250518_153305-a550w6u2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/poschyokotov-hse-university/huggingface/runs/a550w6u2' target=\"_blank\">./big5</a></strong> to <a href='https://wandb.ai/poschyokotov-hse-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/poschyokotov-hse-university/huggingface' target=\"_blank\">https://wandb.ai/poschyokotov-hse-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/poschyokotov-hse-university/huggingface/runs/a550w6u2' target=\"_blank\">https://wandb.ai/poschyokotov-hse-university/huggingface/runs/a550w6u2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1560/1560 20:51, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.679400</td>\n",
              "      <td>0.676662</td>\n",
              "      <td>0.678958</td>\n",
              "      <td>0.678946</td>\n",
              "      <td>0.069000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.663600</td>\n",
              "      <td>0.672133</td>\n",
              "      <td>0.666522</td>\n",
              "      <td>0.666959</td>\n",
              "      <td>0.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.629700</td>\n",
              "      <td>0.681125</td>\n",
              "      <td>0.640565</td>\n",
              "      <td>0.641946</td>\n",
              "      <td>0.061000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.562600</td>\n",
              "      <td>0.710965</td>\n",
              "      <td>0.623693</td>\n",
              "      <td>0.624509</td>\n",
              "      <td>0.069000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.train();      # ~40â€¯min on a T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "OTHCktuFNxAB",
        "outputId": "fa11ba33-9fe0-4d50-ae60-20df0f9b6c2f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:14]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6764523983001709, 'eval_f1_macro': 0.6865878514338156, 'eval_f1_micro': 0.6865651798178555, 'eval_accuracy': 0.0785, 'eval_runtime': 14.2461, 'eval_samples_per_second': 140.389, 'eval_steps_per_second': 17.549, 'epoch': 4.9856}\n"
          ]
        }
      ],
      "source": [
        "print(trainer.evaluate(test_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UKqqR6tgXLYG",
        "outputId": "f7d2c995-893c-4425-aa71-7b3ee45ee89d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "predictions = trainer.predict(test_ds)\n",
        "preds = predictions.predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia-4wyCUXUnR",
        "outputId": "4dd0d178-ac73-48c8-854a-88d4cac309d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:   0.0885\n",
            "F1 (macro): 0.6644\n",
            "F1 (micro): 0.6660\n"
          ]
        }
      ],
      "source": [
        "probs = torch.sigmoid(torch.tensor(preds))\n",
        "\n",
        "threshold = 0.45\n",
        "pred_labels = (probs > threshold).int().numpy()\n",
        "\n",
        "\n",
        "true_labels = np.stack(\n",
        "    [test_df['O'], test_df['C'], test_df['E'], test_df['A'], test_df['N']],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "acc = accuracy_score(true_labels, pred_labels)\n",
        "f1_macro = f1_score(true_labels, pred_labels, average='macro')\n",
        "f1_micro = f1_score(true_labels, pred_labels, average='micro')\n",
        "\n",
        "print(f\"Accuracy:   {acc:.4f}\")\n",
        "print(f\"F1 (macro): {f1_macro:.4f}\")\n",
        "print(f\"F1 (micro): {f1_micro:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GsEjXGh__C7",
        "outputId": "8391b841-d05d-4b49-8f67-e6db83b77424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Per-trait accuracy\n",
            "  O: 0.525\n",
            "  C: 0.526\n",
            "  E: 0.523\n",
            "  A: 0.532\n",
            "  N: 0.568\n",
            "\n",
            "Per-trait precision / recall / F1\n",
            "  O: P=0.524  R=0.870  F1=0.654\n",
            "  C: P=0.523  R=0.940  F1=0.672\n",
            "  E: P=0.518  R=0.983  F1=0.679\n",
            "  A: P=0.527  R=0.979  F1=0.685\n",
            "  N: P=0.584  R=0.687  F1=0.632\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "traits = [\"O\", \"C\", \"E\", \"A\", \"N\"]\n",
        "\n",
        "# ----- per-trait accuracy -------------------------------------------------------\n",
        "trait_acc = {\n",
        "    t: accuracy_score(true_labels[:, j], pred_labels[:, j])\n",
        "    for j, t in enumerate(traits)\n",
        "}\n",
        "\n",
        "print(\"\\nPer-trait accuracy\")\n",
        "for t, a in trait_acc.items():\n",
        "    print(f\"  {t}: {a:.3f}\")\n",
        "\n",
        "# ----- (optional) full per-trait report ----------------------------------------\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "    true_labels, pred_labels, average=None)\n",
        "\n",
        "print(\"Per-trait precision / recall / F1\")\n",
        "for j, t in enumerate(traits):\n",
        "    print(f\"  {t}: P={prec[j]:.3f}  R={rec[j]:.3f}  F1={f1[j]:.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}